{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab1420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "# Utils\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "from timm.utils.model_ema import ModelEmaV3\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac031424",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples= 10_000\n",
    "eeg_features = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]\n",
    "\n",
    "def eeg_from_parquet(\n",
    "    parquet_path: str, display: bool = False, seq_length=50):\n",
    "\n",
    "    # Вырезаем среднюю 50 секундную часть\n",
    "    eeg = pd.read_parquet(parquet_path, columns=eeg_features)\n",
    "    rows = len(eeg)\n",
    "\n",
    "    # начало смещения данных, чтобы забрать середину\n",
    "    offset = (rows - nsamples) // 2\n",
    "\n",
    "    # средние 50 секунд, имеет одинаковое количество показаний слева и справа\n",
    "    eeg = eeg.iloc[offset : offset + nsamples]\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        offset = 0\n",
    "\n",
    "    # Конвертировать в numpy\n",
    "\n",
    "    # создать заполнитель той же формы с нулями\n",
    "    data = np.zeros((nsamples, len(eeg_features)))\n",
    "\n",
    "    for index, feature in enumerate(eeg_features):\n",
    "        x = eeg[feature].values.astype(\"float32\")  # конвертировать в float32\n",
    "\n",
    "        # Вычисляет среднее арифметическое вдоль указанной оси, игнорируя NaN.\n",
    "        mean = np.nanmean(x)\n",
    "        nan_percentage = np.isnan(x).mean()  # percentage of NaN values in feature\n",
    "\n",
    "        # Заполнение значения Nan\n",
    "        # Поэлементная проверка на NaN и возврат результата в виде логического массива.\n",
    "        if nan_percentage < 1:  # если некоторые значения равны Nan, но не все\n",
    "            x = np.nan_to_num(x, nan=mean)\n",
    "        else:  # если все значения — Nan\n",
    "            x[:] = 0\n",
    "        data[:, index] = x\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ceec4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class WidthAttention(nn.Module):\n",
    "    def __init__(self, in_ch, width: int):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, in_ch, kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(in_ch),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_ch, width),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.attention(x)\n",
    "        attention = attention.unsqueeze(1).unsqueeze(1)\n",
    "        return x * attention\n",
    "\n",
    "    \n",
    "class Raw_Signal_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        self.cls= cls\n",
    "        self.model = timm.create_model(model_name, \n",
    "                                       pretrained=True, \n",
    "                                       num_classes=cls,\n",
    "                                       drop_rate= CFG['drop_out'], \n",
    "                                       drop_path_rate= CFG['drop_path'])\n",
    "        \n",
    "        self.gp= self.model.global_pool\n",
    "        self.out= self.model.classifier\n",
    "        self.model.global_pool= nn.Identity()\n",
    "        self.model.classifier= nn.Identity()\n",
    "        self.att= nn.Sequential(\n",
    "                        WidthAttention(self.out.in_features, 313),\n",
    "                    )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)  ## (1,1280,13,21)\n",
    "        x = self.att(x)  ## (1,1280,13,21)\n",
    "        x = self.gp(x)   ## (1,1280)\n",
    "        x = self.out(x)  ## (1,6)\n",
    "        return x if self.training else x.view(-1, self.cls, 1, 1)\n",
    "    \n",
    "    \n",
    "class Transformer_Model(nn.Module):\n",
    "    def __init__(self, cls):\n",
    "        super().__init__()\n",
    "        self.cls= cls\n",
    "        \n",
    "        self.model = timm.create_model('tf_efficientnet_b0_ns', \n",
    "                                       pretrained=True, \n",
    "                                       num_classes=cls,\n",
    "                                       drop_rate= CFG['drop_out'], \n",
    "                                       drop_path_rate= CFG['drop_path'])\n",
    "        self.model.global_pool= nn.Identity()\n",
    "        self.model.classifier= nn.Identity()\n",
    "        \n",
    "        self.posen= PositionalEncoding(1280)\n",
    "        encoder_layer1 = nn.TransformerEncoderLayer(d_model=1280, nhead=8)\n",
    "        self.transformer_encoder1 = nn.TransformerEncoder(encoder_layer1, num_layers=1)\n",
    "        self.fc= nn.Linear(1280, self.cls)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = image\n",
    "        \n",
    "        x = self.model(x).squeeze(dim=-2).permute(0,2,1)\n",
    "        \n",
    "        x = self.posen(x)\n",
    "        x = self.transformer_encoder1(x)\n",
    "        x = self.fc(x.mean(dim=-2))\n",
    "        return x if self.training else x.view(-1, self.cls, 1, 1)\n",
    "    \n",
    "    \n",
    "# model= Raw_Signal_Model('tf_efficientnet_b0_ns', 6)\n",
    "# model= Transformer_Model(6)\n",
    "# x= torch.rand(1,3,20,2000)\n",
    "# model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8881b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(img_size):\n",
    "    return A.Compose([\n",
    "#         A.PadIfNeeded(min_height=8, min_width=CFG['img_crop'], border_mode=0, p=1),\n",
    "#         A.RandomCrop(width=CFG['img_crop'], height=8, p=1),\n",
    "        \n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "        \n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "#         A.PadIfNeeded(min_height=8, min_width=CFG['img_crop'], border_mode=0, p=1),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a153977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, mixup=False):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.mixup= mixup\n",
    "    \n",
    "    def mixup_aug(self, img_1, mask_1, \n",
    "                        img_2, mask_2):\n",
    "        \"\"\"\n",
    "        img: numpy array of shape (height, width,channel)\n",
    "        mask: numpy array of shape (height, width,channel)\n",
    "        \"\"\"\n",
    "        ## mixup\n",
    "        weight= np.random.beta(a=0.5, b=0.5)\n",
    "        img= img_1*weight + img_2*(1-weight)\n",
    "        mask= mask_1*weight + mask_2*(1-weight)\n",
    "        return img, mask\n",
    "    \n",
    "    def read_data(self, data):\n",
    "        def norm_to_standard(img):\n",
    "            ep = 1e-6\n",
    "            m = np.nanmean(img.flatten())\n",
    "            s = np.nanstd(img.flatten())\n",
    "            img = (img-m)/(s+ep)\n",
    "            img = np.nan_to_num(img, nan=0.0)\n",
    "            return img\n",
    "        \n",
    "        img= eeg_from_parquet(data['image_path']).transpose(1,0)\n",
    "        for i in range(img.shape[0]):\n",
    "            img[i]= norm_to_standard(img[i])\n",
    "        img= img[:,:,None]\n",
    "        img= np.concatenate([img, img, img], axis=-1)\n",
    "        label= np.array(eval(data['soft_label']))\n",
    "        return img, label\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.loc[index]\n",
    "        img, label= self.read_data(data)\n",
    "        \n",
    "        # use mixup\n",
    "        if self.mixup and np.random.rand() >= (1-self.mixup) and img.shape[1]<=656:\n",
    "            img_1= img\n",
    "            label_1= np.array(label)\n",
    "            while True:\n",
    "                indx= np.random.randint(len(self.df))\n",
    "                data= self.df.loc[indx]\n",
    "                img_2, label_2= self.read_data(data)\n",
    "                if img_2.shape[1] > img.shape[1]: \n",
    "                    img_2= img_2[:, :img.shape[1]]\n",
    "                    break\n",
    "            img, label= self.mixup_aug(img_1, label_1, \n",
    "                                       img_2, label_2)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': torch.tensor(img, dtype=torch.float32),\n",
    "            'label': torch.tensor(label, dtype=torch.float32),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e62a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_loss(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super().__init__()\n",
    "        self.CrossEntropy= nn.CrossEntropyLoss(weight= None, label_smoothing=0.)\n",
    "        self.FocalCosineLoss= L.FocalCosineLoss()\n",
    "        self.kl_loss = nn.KLDivLoss()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss= 1*self.kl_loss(y_pred.log_softmax(dim=-1), y_true)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f51ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, criterion, optimizer, model_ema):\n",
    "    scaler= amp.GradScaler()\n",
    "    model.train()\n",
    "\n",
    "    ep_loss= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        \n",
    "        with amp.autocast():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "            loss/= CFG['gradient_accumulation']\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (i+1) % CFG['gradient_accumulation']== 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            if model_ema: model_ema.update(model)\n",
    "                \n",
    "    return np.mean(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4efbece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "\n",
    "def valid_epoch(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    ep_loss= []\n",
    "    all_pred= []\n",
    "    all_label= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        all_label.extend(labels.cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds= sliding_window_inference(imgs, \n",
    "                                            roi_size=(-1,CFG['img_crop']), \n",
    "                                            mode= 'gaussian',\n",
    "                                            sw_batch_size=1, \n",
    "                                            predictor=model)\n",
    "            preds= preds.view(preds.shape[0],model.cls,-1).mean(dim=-1)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "        all_pred.extend(preds.cpu().softmax(dim=-1).numpy())\n",
    "    \n",
    "    ## caculate metrics\n",
    "    soft_label= all_label.copy()\n",
    "    all_label= np.array(all_label).argmax(1)\n",
    "    all_pred= np.array(all_pred)\n",
    "    \n",
    "    acc= Accuracy(all_pred, all_label)\n",
    "    print(f'accuracy: {acc}')\n",
    "    recall= Mean_Recall(all_pred, all_label)\n",
    "    print(f'mean_recall: {recall}')\n",
    "    kl_score= kl_divergence(soft_label, all_pred)\n",
    "    print(f'kl_divergence: {kl_score}')\n",
    "    \n",
    "    score= kl_score\n",
    "    return np.mean(ep_loss), score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bde5f",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dbf8757",
   "metadata": {},
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d8029a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG= {\n",
    "    'fold': 0,\n",
    "    'epoch': 20,\n",
    "    \n",
    "    'model_name': 'tf_efficientnet_b0_ns',\n",
    "    'img_size': None,\n",
    "    'img_crop': 10000,\n",
    "    \n",
    "    'batch_size': 16,\n",
    "    'gradient_accumulation': 1,\n",
    "    'gradient_checkpoint': False,\n",
    "    'drop_out': 0.3,\n",
    "    'drop_path': 0.2,\n",
    "    'mixup': 0.,\n",
    "    'EMA': 0.995,\n",
    "    \n",
    "    'lr': 3e-4,\n",
    "    'weight_decay': 0.,\n",
    "    \n",
    "    'num_classes': 6,\n",
    "    'load_model': False,\n",
    "    'save_model': './train_model_copy',\n",
    "    \n",
    "    'finetune': False,\n",
    "}\n",
    "\n",
    "if CFG['finetune']:\n",
    "    print('finetune')\n",
    "    CFG['epoch']= 10\n",
    "    CFG['load_model']= f\"{CFG['save_model']}/cv{CFG['fold']}_best.pth\"\n",
    "    CFG['lr']= 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa7835",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0010c7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 4269\n",
      "valid dataset: 921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>fold</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>time_length</th>\n",
       "      <th>voter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2277392603</td>\n",
       "      <td>924234</td>\n",
       "      <td>../Data/train_eegs/2277392603.parquet</td>\n",
       "      <td>GPD</td>\n",
       "      <td>30539</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0.0, 0.0, 0.45454545454545453, 0.0, 0.0909090...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../Data/train_npy/1.npy</td>\n",
       "      <td>557.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>722738444</td>\n",
       "      <td>999431</td>\n",
       "      <td>../Data/train_eegs/722738444.parquet</td>\n",
       "      <td>LRDA</td>\n",
       "      <td>56885</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.0, 0.0625, 0.0, 0.875, 0.0, 0.0625]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../Data/train_npy/2.npy</td>\n",
       "      <td>568.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374504640</td>\n",
       "      <td>3452193</td>\n",
       "      <td>../Data/train_eegs/374504640.parquet</td>\n",
       "      <td>GRDA</td>\n",
       "      <td>29847</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.0, 0.0, 0.16666666666666666, 0.0, 0.6666666...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>../Data/train_npy/19.npy</td>\n",
       "      <td>582.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1445780287</td>\n",
       "      <td>4004824</td>\n",
       "      <td>../Data/train_eegs/1445780287.parquet</td>\n",
       "      <td>Other</td>\n",
       "      <td>22597</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>../Data/train_npy/20.npy</td>\n",
       "      <td>564.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>893864755</td>\n",
       "      <td>4367732</td>\n",
       "      <td>../Data/train_eegs/893864755.parquet</td>\n",
       "      <td>Other</td>\n",
       "      <td>2338</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.23076923076923078, 0.76...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>../Data/train_npy/23.npy</td>\n",
       "      <td>571.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  spectrogram_id                             image_path   \n",
       "0  2277392603          924234  ../Data/train_eegs/2277392603.parquet  \\\n",
       "1   722738444          999431   ../Data/train_eegs/722738444.parquet   \n",
       "2   374504640         3452193   ../Data/train_eegs/374504640.parquet   \n",
       "3  1445780287         4004824  ../Data/train_eegs/1445780287.parquet   \n",
       "4   893864755         4367732   ../Data/train_eegs/893864755.parquet   \n",
       "\n",
       "  expert_consensus  patient_id  label   \n",
       "0              GPD       30539    2.0  \\\n",
       "1             LRDA       56885    3.0   \n",
       "2             GRDA       29847    4.0   \n",
       "3            Other       22597    5.0   \n",
       "4            Other        2338    5.0   \n",
       "\n",
       "                                          soft_label  fold   \n",
       "0  [0.0, 0.0, 0.45454545454545453, 0.0, 0.0909090...   1.0  \\\n",
       "1             [0.0, 0.0625, 0.0, 0.875, 0.0, 0.0625]   1.0   \n",
       "2  [0.0, 0.0, 0.16666666666666666, 0.0, 0.6666666...   2.0   \n",
       "3                     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   4.0   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.23076923076923078, 0.76...   3.0   \n",
       "\n",
       "                   npy_path  time_length  voter  \n",
       "0   ../Data/train_npy/1.npy        557.0   11.0  \n",
       "1   ../Data/train_npy/2.npy        568.0   16.0  \n",
       "2  ../Data/train_npy/19.npy        582.0   12.0  \n",
       "3  ../Data/train_npy/20.npy        564.0   17.0  \n",
       "4  ../Data/train_npy/23.npy        571.0   13.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('../Data/train_npy.csv')\n",
    "df= df[df['voter']>7]\n",
    "\n",
    "train_df= df[df['fold']!=CFG['fold']].reset_index(drop=True)\n",
    "valid_df= df[df['fold']==CFG['fold']].reset_index(drop=True)\n",
    "valid_df= valid_df.drop_duplicates(subset=['spectrogram_id']).reset_index(drop=True)\n",
    "print(f'train dataset: {len(train_df)}')\n",
    "print(f'valid dataset: {len(valid_df)}')\n",
    "\n",
    "train_dataset= Customize_Dataset(train_df, get_train_transform(CFG['img_size']), mixup=CFG['mixup'])\n",
    "valid_dataset= Customize_Dataset(valid_df, get_test_transform(CFG['img_size']), mixup=False)\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size= CFG['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader= DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e87de6e6",
   "metadata": {},
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "cls_weight= compute_class_weight(class_weight='balanced', \n",
    "                                 classes=list(range(CFG['num_classes'])), \n",
    "                                 y=train_df['label'].values)\n",
    "cls_weight= torch.tensor(cls_weight).cuda()\n",
    "cls_weight"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f9e726b",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data= train_dataset[0]\n",
    "img= data['image']\n",
    "label= data['label']\n",
    "print(img.shape)\n",
    "print(label)\n",
    "plt.imshow(img.permute(1,2,0).numpy()[...,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8144c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce46fc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use EMA: 0.995\n",
      "\n",
      "ep: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3281197856cf4b69b05ae81643eb7bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828b3770c3b14adda55aa0ead4135d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.24104234527687296\n",
      "mean_recall: 0.2410876058579675\n",
      "kl_divergence: 1.07531218572957\n",
      "train loss: 0.10983\n",
      "valid loss: 0.17922, valid_acc: 1.07531\n",
      "model save at score: 1.07531\n",
      "\n",
      "ep: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f10d28bffb466a832202abde0aeae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecf8fab9c52435885d95032f42e8983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5895765472312704\n",
      "mean_recall: 0.2797297530789899\n",
      "kl_divergence: 0.6308234080358068\n",
      "train loss: 0.08269\n",
      "valid loss: 0.10514, valid_acc: 0.63082\n",
      "model save at score: 0.63082\n",
      "\n",
      "ep: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cacf3624134fe4b5fbb954f2655a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8194ee3fa414de5b1858521b907da10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6047774158523345\n",
      "mean_recall: 0.3241537464945872\n",
      "kl_divergence: 0.5937011917312157\n",
      "train loss: 0.07157\n",
      "valid loss: 0.09895, valid_acc: 0.5937\n",
      "model save at score: 0.5937\n",
      "\n",
      "ep: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ac424746cb49dca59ce6d6c5de80e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd62ff8de7b04052858e6cfdaef9b731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6373507057546145\n",
      "mean_recall: 0.3671536744940447\n",
      "kl_divergence: 0.5421598338429052\n",
      "train loss: 0.06343\n",
      "valid loss: 0.09036, valid_acc: 0.54216\n",
      "model save at score: 0.54216\n",
      "\n",
      "ep: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efc373022184fdf8a629b20f63a4f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03497cd3fec244949c28b7b10b764ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6568946796959826\n",
      "mean_recall: 0.3983843334358363\n",
      "kl_divergence: 0.5255691252529925\n",
      "train loss: 0.05669\n",
      "valid loss: 0.08759, valid_acc: 0.52557\n",
      "model save at score: 0.52557\n",
      "\n",
      "ep: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421a6f6605a5494eaf174432186714fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae295cf79ef4d24aefc3972f359b855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6525515743756786\n",
      "mean_recall: 0.4014212002208968\n",
      "kl_divergence: 0.5394992904865191\n",
      "train loss: 0.05088\n",
      "valid loss: 0.08992, valid_acc: 0.5395\n",
      "\n",
      "ep: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c1130209c0468a94fe7788cdbeaf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384d855af74c43bca75b3078cadc3767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6438653637350705\n",
      "mean_recall: 0.3929874441127977\n",
      "kl_divergence: 0.5526290030664559\n",
      "train loss: 0.04582\n",
      "valid loss: 0.0921, valid_acc: 0.55263\n",
      "\n",
      "ep: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576e37a1c0b84471a58e923527e8d475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855a9e20da5f4704b8872b8d33341779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6482084690553745\n",
      "mean_recall: 0.3920462321523798\n",
      "kl_divergence: 0.5542368708224287\n",
      "train loss: 0.04207\n",
      "valid loss: 0.09237, valid_acc: 0.55424\n",
      "\n",
      "ep: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb983f8394684b369d0eee0ff975dd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8994c5e3a648c7be5e96731c5c3d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6514657980456026\n",
      "mean_recall: 0.3934431580549003\n",
      "kl_divergence: 0.5532945601574226\n",
      "train loss: 0.03844\n",
      "valid loss: 0.09222, valid_acc: 0.55329\n",
      "\n",
      "ep: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85432c3a3f824e8a955d09de5025db35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991e29e760f64c61bc63230f8f64bd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6547231270358306\n",
      "mean_recall: 0.40999568254393276\n",
      "kl_divergence: 0.5654962362569478\n",
      "train loss: 0.03422\n",
      "valid loss: 0.09425, valid_acc: 0.5655\n",
      "\n",
      "ep: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441572b0dc55485bba92322996a8f1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4aae6320fc4c4fbfbd5948048a2806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6536373507057546\n",
      "mean_recall: 0.39732591803641126\n",
      "kl_divergence: 0.561824114520448\n",
      "train loss: 0.03267\n",
      "valid loss: 0.09364, valid_acc: 0.56182\n",
      "\n",
      "ep: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dab92ac3324d15aaed157fa828e2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f644c0ec0b94d41bed85ead6fae4499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6568946796959826\n",
      "mean_recall: 0.38913973802566487\n",
      "kl_divergence: 0.5534440388888611\n",
      "train loss: 0.0301\n",
      "valid loss: 0.09224, valid_acc: 0.55344\n",
      "\n",
      "ep: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcb5ce8a01d4594847b424072d2a824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15140\\2722343384.py\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\nep: {ep}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EMA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_ema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15140\\1429300269.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(dataloader, model, criterion, optimizer, model_ema)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mep_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15140\\2859444589.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m## (1,1280,13,21)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m## (1,1280,13,21)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m## (1,1280)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\timm\\models\\efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\timm\\models\\efficientnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckpoint_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\timm\\models\\_efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_pw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_dw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\timm\\layers\\norm_act.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         x = F.batch_norm(\n\u001b[0m\u001b[0;32m    119\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2448\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2450\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2451\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2452\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## create model\n",
    "if CFG['load_model']:\n",
    "    print(f\"load_model: {CFG['load_model']}\")\n",
    "    model= torch.load(CFG['load_model'], map_location= 'cuda')\n",
    "else:\n",
    "    model= Raw_Signal_Model(CFG['model_name'], CFG['num_classes'])\n",
    "#     model= Transformer_Model(CFG['num_classes'])\n",
    "    Transformer_Model\n",
    "    \n",
    "if CFG['gradient_checkpoint']: \n",
    "    print('use gradient checkpoint')\n",
    "    model.model.set_grad_checkpointing(enable=True)\n",
    "    \n",
    "## EMA\n",
    "model.to('cuda')\n",
    "if CFG['EMA']:\n",
    "    print(f\"Use EMA: {CFG['EMA']}\")\n",
    "    model_ema= ModelEmaV3(model, decay=CFG['EMA'])\n",
    "    model_ema.to('cuda')\n",
    "else:\n",
    "    model_ema= type('model_ema', (object,), {'module':{}})\n",
    "    \n",
    "## hyperparameter\n",
    "criterion= Customize_loss()\n",
    "optimizer= optim.AdamW(model.parameters(), lr= CFG['lr'], weight_decay= CFG['weight_decay'])\n",
    "\n",
    "## start training\n",
    "best_score= 100000\n",
    "for ep in range(1, CFG['epoch']+1):\n",
    "    print(f'\\nep: {ep}')\n",
    "    \n",
    "    if CFG['EMA']: train_loss= train_epoch(train_loader, model, criterion, optimizer, model_ema)\n",
    "    else: \n",
    "        train_loss= train_epoch(train_loader, model, criterion, optimizer, False)\n",
    "        model_ema.module= model\n",
    "    valid_loss, valid_acc= valid_epoch(valid_loader, model_ema.module, criterion)\n",
    "    print(f'train loss: {round(train_loss, 5)}')\n",
    "    print(f'valid loss: {round(valid_loss, 5)}, valid_acc: {round(valid_acc, 5)}')\n",
    "    \n",
    "    if valid_acc <= best_score:\n",
    "        best_score= valid_acc\n",
    "        torch.save(model_ema.module, f\"{CFG['save_model']}/cv{CFG['fold']}_best.pth\")\n",
    "        print(f'model save at score: {round(best_score, 5)}')\n",
    "        \n",
    "        ## save model every epoch\n",
    "        torch.save(model_ema.module, f\"{CFG['save_model']}/cv{CFG['fold']}_ep{ep}.pth\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57970596",
   "metadata": {},
   "source": [
    "crop= (20, 20000), no_aug, cv1=0.753, cv2=worse\n",
    "crop= (20, 20000), weak_aug, cv1=0.687, cv2=0.413\n",
    "crop= (20, 20000), weak_aug, cv2=0.458\n",
    "crop= (20, 20000), weak_aug, eeg_unique, cv2=0.445\n",
    "crop= (20, 15000), weak_aug, eeg_unique, cv2=0.449\n",
    "crop= (20, 10000), weak_aug, eeg_unique, cv2=0.438\n",
    "crop= (20, 5000), weak_aug, eeg_unique, cv2=0.451\n",
    "crop= (20, 10000), weak_aug, eeg_unique, att_model, cv2=0.432\n",
    "crop= (20, 10000), weak_aug, eeg_unique, transformer_model, cv2=0.67"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
