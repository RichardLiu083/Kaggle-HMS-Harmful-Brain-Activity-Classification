{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab1420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "from timm.utils.model_ema import ModelEmaV3\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ceec4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class WidthAttention(nn.Module):\n",
    "    def __init__(self, in_ch, width: int):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, in_ch, kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(in_ch),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_ch, width),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.attention(x)\n",
    "        attention = attention.unsqueeze(1).unsqueeze(1)\n",
    "        return x * attention\n",
    "\n",
    "    \n",
    "    \n",
    "class Slide_Window_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        self.cls= cls\n",
    "        self.model = timm.create_model(model_name, \n",
    "                                       pretrained=True, \n",
    "                                       num_classes=cls,\n",
    "                                       drop_rate= CFG['drop_out'], \n",
    "                                       drop_path_rate= CFG['drop_path'])\n",
    "        \n",
    "        self.gp= self.model.global_pool\n",
    "        self.out= self.model.classifier\n",
    "        self.model.global_pool= nn.Identity()\n",
    "        self.model.classifier= nn.Identity()\n",
    "        self.att= nn.Sequential(\n",
    "                        WidthAttention(self.out.in_features, 29),\n",
    "                    )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)  ## (1,1280,13,21)\n",
    "        x = self.att(x)  ## (1,1280,13,21)\n",
    "        x = self.gp(x)   ## (1,1280)\n",
    "        x = self.out(x)  ## (1,6)\n",
    "        return x if self.training else x.view(-1, self.cls, 1, 1)\n",
    "    \n",
    "    \n",
    "# attention= Slide_Window_Model('tf_efficientnet_b0_ns', 6)\n",
    "# x= torch.rand(1,3,400,656)\n",
    "# attention(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8881b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"num_masks_x\": (1, 10),\n",
    "#     \"num_masks_y\": (1, 5),    \n",
    "#     \"mask_y_length\": (5, 10),\n",
    "    \"mask_x_length\": (5, 10),\n",
    "    \"fill_value\": 0,\n",
    "}\n",
    "\n",
    "def get_train_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.PadIfNeeded(min_height=400, min_width=CFG['img_crop'], border_mode=0, p=1),\n",
    "        A.RandomCrop(width=CFG['img_crop'], height=400, p=1),\n",
    "        \n",
    "        A.RandomBrightnessContrast(brightness_limit=0.6, contrast_limit=0., p=0.5),\n",
    "        \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.XYMasking(**params, p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.05, rotate_limit= 15,\n",
    "                                        interpolation=cv2.INTER_LINEAR, border_mode=0, p=0.7),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.PadIfNeeded(min_height=400, min_width=CFG['img_crop'], border_mode=0, p=1),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a153977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import spectrogram_from_eeg\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, training=False):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.training= training\n",
    "    \n",
    "    def mixup_aug(self, img_1, mask_1, \n",
    "                        img_2, mask_2):\n",
    "        \"\"\"\n",
    "        img: numpy array of shape (height, width,channel)\n",
    "        mask: numpy array of shape (height, width,channel)\n",
    "        \"\"\"\n",
    "        ## mixup\n",
    "        weight= np.random.beta(a=0.5, b=0.5)\n",
    "        img= img_1*weight + img_2*(1-weight)\n",
    "        mask= mask_1*weight + mask_2*(1-weight)\n",
    "        return img, mask\n",
    "    \n",
    "    def read_data(self, data):\n",
    "        img= np.load(data['npy_path'])\n",
    "        label= np.array(eval(data['soft_label']))\n",
    "        return img, label\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.loc[index]\n",
    "        img, label= self.read_data(data)\n",
    "        \n",
    "        # use mixup\n",
    "        if self.training and np.random.rand() >= (1-CFG['mixup']) and img.shape[1]<=656:\n",
    "            img_1= img\n",
    "            label_1= np.array(label)\n",
    "            while True:\n",
    "                indx= np.random.randint(len(self.df))\n",
    "                data= self.df.loc[indx]\n",
    "                img_2, label_2= self.read_data(data)\n",
    "                if img_2.shape[1] > img.shape[1]: \n",
    "                    img_2= img_2[:, :img.shape[1]]\n",
    "                    break\n",
    "            img, label= self.mixup_aug(img_1, label_1, \n",
    "                                       img_2, label_2)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': torch.tensor(img, dtype=torch.float32),\n",
    "            'label': torch.tensor(label, dtype=torch.float32),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e62a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_loss(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super().__init__()\n",
    "        self.CrossEntropy= nn.CrossEntropyLoss(weight= None, label_smoothing=0.)\n",
    "        self.FocalCosineLoss= L.FocalCosineLoss()\n",
    "        self.kl_loss = nn.KLDivLoss()\n",
    "        self.bce= nn.BCELoss()\n",
    "        self.mse= nn.MSELoss()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss= 1*self.kl_loss(y_pred.log_softmax(dim=-1), y_true) + 1*self.mse(y_pred.softmax(dim=-1), y_true)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f51ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, criterion, optimizer, model_ema):\n",
    "    scaler= amp.GradScaler()\n",
    "    model.train()\n",
    "\n",
    "    ep_loss= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        \n",
    "        with amp.autocast():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "            loss/= CFG['gradient_accumulation']\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (i+1) % CFG['gradient_accumulation']== 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            if model_ema: model_ema.update(model)\n",
    "                \n",
    "    return np.mean(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efbece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "\n",
    "def valid_epoch(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    ep_loss= []\n",
    "    all_pred= []\n",
    "    all_label= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        all_label.extend(labels.cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds= sliding_window_inference(imgs, \n",
    "                                            roi_size=(-1,CFG['img_crop']), \n",
    "                                            mode= 'gaussian',\n",
    "                                            sw_batch_size=1, \n",
    "                                            predictor=model)\n",
    "            preds= preds.view(preds.shape[0],model.cls,-1).mean(dim=-1)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "        all_pred.extend(preds.cpu().softmax(dim=-1).numpy())\n",
    "    \n",
    "    ## caculate metrics\n",
    "    soft_label= all_label.copy()\n",
    "    all_label= np.array(all_label).argmax(1)\n",
    "    all_pred= np.array(all_pred)\n",
    "    \n",
    "    acc= Accuracy(all_pred, all_label)\n",
    "    print(f'accuracy: {acc}')\n",
    "    recall= Mean_Recall(all_pred, all_label)\n",
    "    print(f'mean_recall: {recall}')\n",
    "    kl_score= kl_divergence(soft_label, all_pred)\n",
    "    print(f'kl_divergence: {kl_score}')\n",
    "    \n",
    "    score= kl_score\n",
    "    return np.mean(ep_loss), score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bde5f",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f04875d7",
   "metadata": {},
   "source": [
    "[m for m in timm.list_models(pretrained=True) if 'v2' in m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d8029a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune\n"
     ]
    }
   ],
   "source": [
    "CFG= {\n",
    "    'fold': 3,\n",
    "    'epoch': 25,\n",
    "    'model_name': 'tf_efficientnet_b0_ns',\n",
    "    \n",
    "    'img_size': None,\n",
    "    'img_crop': 912,\n",
    "    \n",
    "    'batch_size': 16,\n",
    "    'gradient_accumulation': 1,\n",
    "    'gradient_checkpoint': False,\n",
    "    'drop_out': 0.3,\n",
    "    'drop_path': 0.2,\n",
    "    'mixup': 0.3,\n",
    "    'EMA': 0.995,\n",
    "    \n",
    "    'lr': 3e-4,\n",
    "    'weight_decay': 0.,\n",
    "    \n",
    "    'num_classes': 6,\n",
    "    'load_model': False,\n",
    "    'save_model': './train_model',\n",
    "    \n",
    "    'finetune': True,\n",
    "}\n",
    "\n",
    "if CFG['finetune']:\n",
    "    print('finetune')\n",
    "    CFG['epoch']= 15\n",
    "    CFG['load_model']= f\"{CFG['save_model']}/cv{CFG['fold']}_best.pth\"\n",
    "    CFG['lr']= 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa7835",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0010c7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 3479\n",
      "valid dataset: 909\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>fold</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>time_length</th>\n",
       "      <th>voter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2277392603</td>\n",
       "      <td>924234</td>\n",
       "      <td>../Data/train_eegs/2277392603.parquet</td>\n",
       "      <td>GPD</td>\n",
       "      <td>30539</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0.0, 0.0, 0.45454545454545453, 0.0, 0.0909090...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../Data/train_npy/1.npy</td>\n",
       "      <td>557.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>722738444</td>\n",
       "      <td>999431</td>\n",
       "      <td>../Data/train_eegs/722738444.parquet</td>\n",
       "      <td>LRDA</td>\n",
       "      <td>56885</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.0, 0.0625, 0.0, 0.875, 0.0, 0.0625]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../Data/train_npy/2.npy</td>\n",
       "      <td>568.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1202099836</td>\n",
       "      <td>1353070</td>\n",
       "      <td>../Data/train_eegs/1202099836.parquet</td>\n",
       "      <td>Other</td>\n",
       "      <td>34554</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0.0, 0.0, 0.35714285714285715, 0.0, 0.0, 0.64...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../Data/train_npy/7.npy</td>\n",
       "      <td>556.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>374504640</td>\n",
       "      <td>3452193</td>\n",
       "      <td>../Data/train_eegs/374504640.parquet</td>\n",
       "      <td>GRDA</td>\n",
       "      <td>29847</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.0, 0.0, 0.16666666666666666, 0.0, 0.6666666...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>../Data/train_npy/19.npy</td>\n",
       "      <td>582.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1445780287</td>\n",
       "      <td>4004824</td>\n",
       "      <td>../Data/train_eegs/1445780287.parquet</td>\n",
       "      <td>Other</td>\n",
       "      <td>22597</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>../Data/train_npy/20.npy</td>\n",
       "      <td>564.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  spectrogram_id                             image_path   \n",
       "0  2277392603          924234  ../Data/train_eegs/2277392603.parquet  \\\n",
       "1   722738444          999431   ../Data/train_eegs/722738444.parquet   \n",
       "2  1202099836         1353070  ../Data/train_eegs/1202099836.parquet   \n",
       "3   374504640         3452193   ../Data/train_eegs/374504640.parquet   \n",
       "4  1445780287         4004824  ../Data/train_eegs/1445780287.parquet   \n",
       "\n",
       "  expert_consensus  patient_id  label   \n",
       "0              GPD       30539    2.0  \\\n",
       "1             LRDA       56885    3.0   \n",
       "2            Other       34554    5.0   \n",
       "3             GRDA       29847    4.0   \n",
       "4            Other       22597    5.0   \n",
       "\n",
       "                                          soft_label  fold   \n",
       "0  [0.0, 0.0, 0.45454545454545453, 0.0, 0.0909090...   1.0  \\\n",
       "1             [0.0, 0.0625, 0.0, 0.875, 0.0, 0.0625]   1.0   \n",
       "2  [0.0, 0.0, 0.35714285714285715, 0.0, 0.0, 0.64...   0.0   \n",
       "3  [0.0, 0.0, 0.16666666666666666, 0.0, 0.6666666...   2.0   \n",
       "4                     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   4.0   \n",
       "\n",
       "                   npy_path  time_length  voter  \n",
       "0   ../Data/train_npy/1.npy        557.0   11.0  \n",
       "1   ../Data/train_npy/2.npy        568.0   16.0  \n",
       "2   ../Data/train_npy/7.npy        556.0   14.0  \n",
       "3  ../Data/train_npy/19.npy        582.0   12.0  \n",
       "4  ../Data/train_npy/20.npy        564.0   17.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('../Data/train_npy.csv')\n",
    "if CFG['finetune']: df= df[df['voter']>7]\n",
    "df= df.drop_duplicates(subset=['spectrogram_id'])\n",
    "\n",
    "train_df= df[df['fold']!=CFG['fold']].reset_index(drop=True)\n",
    "valid_df= df[df['fold']==CFG['fold']].reset_index(drop=True)\n",
    "print(f'train dataset: {len(train_df)}')\n",
    "print(f'valid dataset: {len(valid_df)}')\n",
    "\n",
    "train_dataset= Customize_Dataset(train_df, get_train_transform(CFG['img_size']), training=True)\n",
    "valid_dataset= Customize_Dataset(valid_df, get_test_transform(CFG['img_size']), training=False)\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size= CFG['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader= DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5036ed85",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data= train_dataset[0]\n",
    "img= data['image']\n",
    "label= data['label']\n",
    "print(img.shape)\n",
    "print(label)\n",
    "plt.imshow(img.permute(1,2,0).numpy()[...,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8144c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce46fc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_model: ./train_model/cv3_best.pth\n",
      "Use EMA: 0.995\n",
      "\n",
      "ep: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8325d0dff34e4c81cd2297e7d6ae79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0e3c83d0ae4918b6daa9845c837cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7645764576457645\n",
      "mean_recall: 0.6428939984702583\n",
      "kl_divergence: 0.32022699516384867\n",
      "train loss: 0.07484\n",
      "valid loss: 0.07311, valid_acc: 0.32023\n",
      "model save at score: 0.32023\n",
      "\n",
      "ep: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c1fe181cf746e9ad933bb70a9e2841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dabd5b6807489aa8546360f22aa846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7645764576457645\n",
      "mean_recall: 0.6173139176386565\n",
      "kl_divergence: 0.30550743175527456\n",
      "train loss: 0.06753\n",
      "valid loss: 0.06947, valid_acc: 0.30551\n",
      "model save at score: 0.30551\n",
      "\n",
      "ep: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae69a33bc5b34d71b77a5b7be2eeb2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da75fe594d784e3ebfe069cd29caa9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.759075907590759\n",
      "mean_recall: 0.5955208869040572\n",
      "kl_divergence: 0.3010498697568742\n",
      "train loss: 0.06604\n",
      "valid loss: 0.06841, valid_acc: 0.30105\n",
      "model save at score: 0.30105\n",
      "\n",
      "ep: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02bc2250b0e4ee0a141ff1f9c5d4ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60053698a55417aad4c7809fd8b65c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7645764576457645\n",
      "mean_recall: 0.5946940442321155\n",
      "kl_divergence: 0.29507376699802923\n",
      "train loss: 0.06428\n",
      "valid loss: 0.06685, valid_acc: 0.29507\n",
      "model save at score: 0.29507\n",
      "\n",
      "ep: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd3ba78bb664c26b9a59e7b4c66bf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea63421cb5b04759aef049132fa5ceca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7612761276127613\n",
      "mean_recall: 0.5990253447937619\n",
      "kl_divergence: 0.283188968563356\n",
      "train loss: 0.0606\n",
      "valid loss: 0.064, valid_acc: 0.28319\n",
      "model save at score: 0.28319\n",
      "\n",
      "ep: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62d5c4e77f14b8ab560a97406ff21f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b08a98666840adb82ed8998b3131de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7678767876787679\n",
      "mean_recall: 0.6137866440540306\n",
      "kl_divergence: 0.28703724947100084\n",
      "train loss: 0.05942\n",
      "valid loss: 0.06502, valid_acc: 0.28704\n",
      "\n",
      "ep: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8985ef80bc1e42e1a0453ef95d419097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da214b43e4f74511842960383a5bdd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.77007700770077\n",
      "mean_recall: 0.6123650070901565\n",
      "kl_divergence: 0.2874848460811262\n",
      "train loss: 0.05844\n",
      "valid loss: 0.0651, valid_acc: 0.28748\n",
      "\n",
      "ep: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6766ff40dbe471ebcbb863440a9a4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44579df03b54236947372603790d2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7733773377337734\n",
      "mean_recall: 0.6229900770820835\n",
      "kl_divergence: 0.2904475141850841\n",
      "train loss: 0.05583\n",
      "valid loss: 0.06586, valid_acc: 0.29045\n",
      "\n",
      "ep: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21244c1ea27d4d6a9572042608aa405c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edea741c2674c91a8a1be98def9d4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.77007700770077\n",
      "mean_recall: 0.6327504736399286\n",
      "kl_divergence: 0.2892201899082976\n",
      "train loss: 0.05576\n",
      "valid loss: 0.06557, valid_acc: 0.28922\n",
      "\n",
      "ep: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce4eeb3c6ae4dae91b3ea55e0a58c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6440a54eba43de92a40388df4dc72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7667766776677668\n",
      "mean_recall: 0.6185839686715925\n",
      "kl_divergence: 0.2969591353384674\n",
      "train loss: 0.05494\n",
      "valid loss: 0.06732, valid_acc: 0.29696\n",
      "\n",
      "ep: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eee836e4de14412b11eb1651bb1c035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883adbfa1c774b84bbed48bc45aa8662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7645764576457645\n",
      "mean_recall: 0.6200233898195767\n",
      "kl_divergence: 0.298410067001686\n",
      "train loss: 0.05438\n",
      "valid loss: 0.06755, valid_acc: 0.29841\n",
      "\n",
      "ep: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e488a6b7304209be438cde806e391d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0366dc7db174b789dd3c5dce21729b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7678767876787679\n",
      "mean_recall: 0.6190955362513506\n",
      "kl_divergence: 0.30190011652476184\n",
      "train loss: 0.051\n",
      "valid loss: 0.06872, valid_acc: 0.3019\n",
      "\n",
      "ep: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f78b40116ab4d37a991cdc6c394d8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13acffabdc7246b78fb15e901957d510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.77007700770077\n",
      "mean_recall: 0.6287466006542702\n",
      "kl_divergence: 0.301617851499064\n",
      "train loss: 0.04988\n",
      "valid loss: 0.06865, valid_acc: 0.30162\n",
      "\n",
      "ep: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd89bd43eae4eabab98bfabf7b5f49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d2326ed8824d09ab3f32df48c63165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7612761276127613\n",
      "mean_recall: 0.618615418601107\n",
      "kl_divergence: 0.30917792404476907\n",
      "train loss: 0.04831\n",
      "valid loss: 0.07053, valid_acc: 0.30918\n",
      "\n",
      "ep: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e521ffa18b433095ddc894d86433f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d8b20f0e954b9d9848327ebb37f7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7535753575357536\n",
      "mean_recall: 0.6268568066437803\n",
      "kl_divergence: 0.3130863177195205\n",
      "train loss: 0.04849\n",
      "valid loss: 0.07143, valid_acc: 0.31309\n"
     ]
    }
   ],
   "source": [
    "## create model\n",
    "if CFG['load_model']:\n",
    "    print(f\"load_model: {CFG['load_model']}\")\n",
    "    model= torch.load(CFG['load_model'], map_location= 'cuda')\n",
    "else:\n",
    "    model= Slide_Window_Model(CFG['model_name'], CFG['num_classes'])\n",
    "    \n",
    "if CFG['gradient_checkpoint']: \n",
    "    print('use gradient checkpoint')\n",
    "    model.model.set_grad_checkpointing(enable=True)\n",
    "    \n",
    "## EMA\n",
    "model.to('cuda')\n",
    "if CFG['EMA']:\n",
    "    print(f\"Use EMA: {CFG['EMA']}\")\n",
    "    model_ema= ModelEmaV3(model, decay=CFG['EMA'])\n",
    "    model_ema.to('cuda')\n",
    "else:\n",
    "    model_ema= type('model_ema', (object,), {'module':{}})\n",
    "    \n",
    "## hyperparameter\n",
    "criterion= Customize_loss()\n",
    "optimizer= optim.AdamW(model.parameters(), lr= CFG['lr'], weight_decay= CFG['weight_decay'])\n",
    "\n",
    "## start training\n",
    "best_score= 100000\n",
    "for ep in range(1, CFG['epoch']+1):\n",
    "    print(f'\\nep: {ep}')\n",
    "    \n",
    "    if CFG['EMA']: train_loss= train_epoch(train_loader, model, criterion, optimizer, model_ema)\n",
    "    else: \n",
    "        train_loss= train_epoch(train_loader, model, criterion, optimizer, False)\n",
    "        model_ema.module= model\n",
    "    valid_loss, valid_acc= valid_epoch(valid_loader, model_ema.module, criterion)\n",
    "    print(f'train loss: {round(train_loss, 5)}')\n",
    "    print(f'valid loss: {round(valid_loss, 5)}, valid_acc: {round(valid_acc, 5)}')\n",
    "    \n",
    "    if valid_acc <= best_score:\n",
    "        best_score= valid_acc\n",
    "        torch.save(model_ema.module, f\"{CFG['save_model']}/cv{CFG['fold']}_best.pth\")\n",
    "        print(f'model save at score: {round(best_score, 5)}')\n",
    "        \n",
    "        ## save model every epoch\n",
    "#         torch.save(model_ema.module, f\"{CFG['save_model']}/cv{CFG['fold']}_ep{ep}.pth\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76b07cb8",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "path= 'train_model/cv0_best.pth'\n",
    "\n",
    "example = torch.rand(1, 3, 400, 912)\n",
    "model= torch.load(path).cpu().eval()\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module.save(path.replace('pth', 'ts'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be6f6cab",
   "metadata": {},
   "source": [
    "effb0:\n",
    "imgsz= x-concat, crop=(400,256), soft_label, weak_aug, KL_loss, eeg_data, cv=0.691\n",
    "imgsz= x-concat, crop=(512,256), soft_label, weak_aug, KL_loss, eeg_data, cv=0.694, lb=0.54\n",
    "imgsz= x-concat, crop=(400,256), soft_label, weak_aug, KL_loss, eeg_data, EMA=0.995, cv=0.706, lb=0.52\n",
    "\n",
    "\n",
    "imgsz= x+z-concat, crop=(400,256), soft_label, weak_aug, KL_loss, spectrogram+eeg_data, cv=0.860\n",
    "imgsz= z-concat, crop=(100,256), soft_label, weak_aug, KL_loss, spectrogram+eeg_data, cv=0.953\n",
    "imgsz= x-concat, crop=(800,256), soft_label, weak_aug, KL_loss, spectrogram+eeg_data, cv=0.731, lb=0.56\n",
    "\n",
    "\n",
    "x+y-concat, soft_label, KL_loss, spec+eeg_data, EMA=0.995:\n",
    "crop=(400,512), weak_aug, cv=0.642, lb=0.54\n",
    "crop=(400,556), weak_aug, cv=0.644, lb=0.54\n",
    "crop=(400,656), weak_aug, cv=0.610, lb=0.47\n",
    "crop=(400,756), weak_aug, cv=0.631\n",
    "crop=(400,656), weak_aug, with dup., cv=0.623, lb=0.47\n",
    "crop=(400,656), weak_aug, mixup=0.3, cv=0.597, lb=0.45\n",
    "crop=(400,656), weak_aug, mixup=0.5, cv=0.606\n",
    "crop=(400,656), weak_aug, mixup=0.7, cv=0.613\n",
    "crop=(400,656), weak_aug, mixup=0.3, BC_model, cv=0.651\n",
    "crop=(400,656), weak_aug, mixup=0.3, cutup, cv=0.603\n",
    "crop=(400,656), weak_aug, mixup=0.3, tl<1000, cv=0.607\n",
    "crop=(400,656), weak_aug, mixup=0.3, tl<800, cv=0.0.615\n",
    "crop=(400,656), strong_aug, mixup=0.3, cv=0.583\n",
    "crop=(400,656), strong_aug, mixup=0.3, 2s_voter>7, cv1=0.583, cv2=0.313, lb=0.38\n",
    "crop=(400,656), strong_aug, mixup=0.3, voter>7, cv2=0.315, lb=0.39\n",
    "crop=(400,656), strong_aug, mixup=0.3, SED_model, 2s_voter>7, cv1=0.578, cv2=worse, lb=sum to 1 error\n",
    "crop=(400,656), strong_aug, mixup=0.3, sigmoid_attention, 2s_voter>7, cv1=0.575, cv2=0.311, lb=0.38\n",
    "crop=(400,656), strong_aug, mixup=0.3, softmax_attention, 2s_voter>7, cv1=0.575, cv2=worse\n",
    "crop=(400,656), strong_aug, mixup=0.3, sigmoid_attention, 2s_voter>7, eeg_unique, cv1=0.587, cv2=worse\n",
    "crop=(400,656), strong_aug, mixup=0.3, sigmoid_attention, 2s_voter>7, kl+mse_loss, cv1=0.573, cv2=0.307, lb=0.37\n",
    "crop=(400,656), strong_aug, mixup=0.3, sigmoid_attention, 2s_voter>12, kl+mse_loss, cv1=0.573, cv2=0.293, lb=0.38\n",
    "crop=(400,656), strong_aug, mixup=0.3, sigmoid_attention, drop prob=1, kl+mse_loss, cv1=0.573, cv2=0.428, lb=0.38\n",
    "crop=(400,656), strong_aug, mixup=0.3, sigmoid_attention, 2s_voter<7_PL, kl+mse_loss, cv1=0.573, cv2=0.282, lb=0.37\n",
    "crop=(400,656), strong_aug, mixup=0.3, sigmoid_attention, 2s_voter<7_self_PL, kl+mse_loss, cv1=0.573, cv2=0.301, lb=0.36\n",
    "\n",
    "crop=(400,656), strong_aug, mixup=0.3, sigmoid_attention, x+y-concat, soft_label, spec+eeg_data, EMA=0.995:\n",
    "log&norm_to_eeg, 2s_voter>7, kl+mse_loss, cv1=0.570, cv2=0.296, lb=0.37  ## cv1, cv2 worse\n",
    "10_sec_eeg+spec, kl+mse_loss, cv1=0.576\n",
    "10_50_sec_eeg+spec, kl+mse_loss, cv1=0.547, cv2=0.305, lb=0.35\n",
    "10_30_sec_eeg+spec, H_concat, kl+mse_loss, cv1=0.560, cv2=0.296, lb=0.35\n",
    "10_20_30_40_sec_eeg+spec, HV_concat, kl+mse_loss, cv1=0.549, cv2=0.297, lb=0.36\n",
    "10_20_30_40_sec_eeg+spec, Hv_concat, kl+mse_loss, cv1=0.543, cv2=0.298, lb=0.36"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
