{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import  matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/monai-019/')\n",
    "\n",
    "import shutil\n",
    "shutil.copy('/kaggle/input/eeg2spectrogram/preprocessing.py','preprocessing.py')\n",
    "from preprocessing import spectrogram_from_eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Slide_Window_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x.view(-1, self.cls, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.PadIfNeeded(min_height=400, min_width=CFG['img_crop'], border_mode=0, p=1),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def read_data(self, data):\n",
    "        def norm_to_255(img):\n",
    "            img= img-img.min()\n",
    "            img= img/img.max()\n",
    "            img= img*255\n",
    "            return img.astype(np.uint8)\n",
    "        \n",
    "        def norm_to_standard(img):\n",
    "            ep = 1e-6\n",
    "            m = np.nanmean(img.flatten())\n",
    "            s = np.nanstd(img.flatten())\n",
    "            img = (img-m)/(s+ep)\n",
    "            img = np.nan_to_num(img, nan=0.0)\n",
    "            return img\n",
    "        \n",
    "        raw= pd.read_parquet(data['spectrogram_path']).fillna(0)\n",
    "        \n",
    "        col= list(raw.filter(like='LL', axis=1))\n",
    "        img_LL= np.log1p(raw[col].T.values)\n",
    "        col= list(raw.filter(like='RL', axis=1))\n",
    "        img_RL= np.log1p(raw[col].T.values)\n",
    "        col= list(raw.filter(like='RP', axis=1))\n",
    "        img_RP= np.log1p(raw[col].T.values)\n",
    "        col= list(raw.filter(like='LP', axis=1))\n",
    "        img_LP= np.log1p(raw[col].T.values)\n",
    "        \n",
    "        img= np.concatenate([img_LL, img_LP, img_RP, img_RL], axis=0)\n",
    "        img= np.expand_dims(img, axis=2)\n",
    "        img= np.concatenate([img, img, img], axis=2)\n",
    "        img_spectrograms= norm_to_standard(img)\n",
    "        \n",
    "        ## test_eegs\n",
    "        img_10= spectrogram_from_eeg(data['eeg_path'], duration=10, height=100)\n",
    "        img_10= np.concatenate([img_10[..., 0],\n",
    "                                img_10[..., 1],\n",
    "                                img_10[..., 2],\n",
    "                                img_10[..., 3]], axis=0)\n",
    "        img_30= spectrogram_from_eeg(data['eeg_path'], duration=30, height=100)\n",
    "        img_30= np.concatenate([img_30[..., 0],\n",
    "                                img_30[..., 1],\n",
    "                                img_30[..., 2],\n",
    "                                img_30[..., 3]], axis=0)\n",
    "        img= np.concatenate([img_10, img_30], axis=1)\n",
    "        img= np.expand_dims(img, axis=2)\n",
    "        img= np.concatenate([img, img, img], axis=2)\n",
    "        img_eeg= img\n",
    "        \n",
    "        ## fuse img\n",
    "        img_spectrograms= img_spectrograms[:, :, :1]\n",
    "        img_eeg= img_eeg[..., :1]\n",
    "        img= np.concatenate([img_eeg, img_spectrograms], axis=1)\n",
    "        img= np.concatenate([img, img, img], axis=2)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.loc[index]\n",
    "        img= self.read_data(data)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': torch.tensor(img, dtype=torch.float32),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG= {\n",
    "    'img_size': None,\n",
    "    'img_crop': 912,\n",
    "    'TTA': 1,\n",
    "    \n",
    "    'model': [\n",
    "        '/kaggle/input/effb0-lb33',\n",
    "        '/kaggle/input/effb0-kd-lb32',\n",
    "        '/kaggle/input/cvnxt-kd-lb32',\n",
    "        '/kaggle/input/effv2s-kd-lb31',\n",
    "        \n",
    "        '/kaggle/input/effb0-1',\n",
    "    ],\n",
    "    'model_weight': [\n",
    "        0.1,\n",
    "        0.1,\n",
    "        0.1,\n",
    "        0.2,\n",
    "        \n",
    "        0.5,\n",
    "    ],\n",
    "}\n",
    "\n",
    "## load model\n",
    "Models= []\n",
    "for i in range(len(CFG['model'])):\n",
    "    models= []\n",
    "    for m in glob.glob(CFG['model'][i]+'/**'):\n",
    "        models.append( torch.load(m, map_location= 'cuda:0') )\n",
    "    Models.append(models)\n",
    "CFG['model']= Models\n",
    "print(f\"length of model: {len(Models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df= pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n",
    "spectrogram_path= '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms'\n",
    "eeg_path= '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n",
    "for i in range(len(test_df)):\n",
    "    test_df.loc[i,'spectrogram_path']= f\"{spectrogram_path}/{test_df.loc[i,'spectrogram_id']}.parquet\"\n",
    "    test_df.loc[i,'eeg_path']= f\"{eeg_path}/{test_df.loc[i,'eeg_id']}.parquet\"\n",
    "    \n",
    "test_dataset= Customize_Dataset(test_df, get_test_transform(CFG['img_size']))\n",
    "test_loader= DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "def sliding_inference(model, img):\n",
    "    \n",
    "    img= torch.unsqueeze(img, 0).cuda()\n",
    "    for i, m in enumerate(model):\n",
    "        with torch.no_grad():\n",
    "            m.eval()\n",
    "            \n",
    "            imgs= torch.cat([img, img.flip(-1), img.flip(-2), img.flip(-1).flip(-2)], dim=0)\n",
    "            with torch.no_grad():\n",
    "                pred= sliding_window_inference(imgs[:CFG['TTA']],\n",
    "                                                roi_size=(-1,CFG['img_crop']), \n",
    "                                                mode= 'gaussian',\n",
    "                                                sw_batch_size=4, \n",
    "                                                predictor=m)\n",
    "                pred= pred.view(pred.shape[0],6,-1).mean(dim=-1)\n",
    "                pred= pred.mean(dim=0)\n",
    "            \n",
    "        if i==0: preds= pred.softmax(dim=-1)\n",
    "        else: preds+= pred.softmax(dim=-1)\n",
    "            \n",
    "    preds= preds/len(model)\n",
    "    preds= preds.cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count= 0\n",
    "for i, data in enumerate(tqdm(test_loader)):\n",
    "    for j in range(len(data['image'])):\n",
    "        img= data['image'][j]\n",
    "        if count==0: print(img.shape)\n",
    "            \n",
    "        ## Model Inference\n",
    "        for k,m in enumerate(CFG['model']):\n",
    "            prob= sliding_inference(m, img)\n",
    "            \n",
    "            if k==0: pred= prob * CFG['model_weight'][k]\n",
    "            else: pred+= prob * CFG['model_weight'][k]\n",
    "                \n",
    "        test_df.loc[count, 'pred_cls']= pred.argmax(0)\n",
    "        test_df.loc[count, 'prob']= str(pred.tolist())\n",
    "        count+= 1\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit= pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv')\n",
    "for i in range(len(submit)):\n",
    "    pred= eval(test_df.loc[i, 'prob'])\n",
    "    submit.loc[i, submit.columns[1:] ]= pred\n",
    "    \n",
    "submit.to_csv('submission_richard_lb31.csv',index=False)\n",
    "submit"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 3180971,
     "sourceId": 5516047,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4424000,
     "sourceId": 7987891,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4739495,
     "sourceId": 8039081,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4739503,
     "sourceId": 8039092,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4740843,
     "sourceId": 8041169,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4742279,
     "sourceId": 8043169,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4742830,
     "sourceId": 8043928,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4751510,
     "sourceId": 8056136,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
